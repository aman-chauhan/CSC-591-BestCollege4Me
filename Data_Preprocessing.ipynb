{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/MERGED2015_16_PP.csv\"\n",
    "data = pd.read_csv(path, low_memory=False)\n",
    "\n",
    "path_2014 = \"data/MERGED2013_14_PP.csv\"\n",
    "data_2014 = pd.read_csv(path_2014, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing out columns of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"OPEID\", \"UNITID\", \"INSTNM\", \"CITY\", \"STABBR\", \"ZIP\", \"CURROPER\", \"MAIN\", \"PREDDEG\", \"HIGHDEG\", \n",
    "        \"CONTROL\", \"RELAFFIL\", \"DISTANCEONLY\", \"ADM_RATE\", \"SAT_AVG\", \"ACTCMMID\", \"UGDS\", \"UGDS_WHITE\", \"UGDS_BLACK\", \"UGDS_HISP\", \n",
    "        \"UGDS_ASIAN\", \"UGDS_AIAN\", \"UGDS_NHPI\", \"UGDS_2MOR\", \"UGDS_NRA\", \"UGDS_UNKN\", \n",
    "        \"HBCU\", \"PBI\", \"ANNHI\", \"TRIBAL\", \"HSI\", \"NANTI\", \"MENONLY\", \"WOMENONLY\", \"PPTUG_EF\", \n",
    "        \"UG25ABV\", \"INC_PCT_LO\", \"INC_PCT_M1\", \"INC_PCT_M2\", \"INC_PCT_H1\", \"INC_PCT_H2\", \n",
    "        \"PAR_ED_PCT_1STGEN\", \"NPT4_PUB\", \"NPT4_PRIV\", \"COSTT4_A\", \"TUITIONFEE_IN\", \"TUITIONFEE_OUT\", \n",
    "        \"NPT41_PUB\", \"NPT42_PUB\", \"NPT43_PUB\", \"NPT44_PUB\", \"NPT45_PUB\", \"NPT41_PRIV\", \"NPT42_PRIV\", \n",
    "        \"NPT43_PRIV\", \"NPT44_PRIV\", \"NPT45_PRIV\", \"PCTFLOAN\", \"PCTPELL\", \"GRAD_DEBT_MDN\", \n",
    "        \"WDRAW_DEBT_MDN\", \"GRAD_DEBT_MDN10YR\", \"CDR3\", \"RPY_3YR_RT\", \n",
    "        \"RPY_5YR_RT\", \"RPY_7YR_RT\", \"C150_4\", \"D150_4\", \"CIP01BACHL\", \"CIP03BACHL\", \"CIP04BACHL\", \"CIP05BACHL\", \"CIP09BACHL\", \n",
    "        \"CIP10BACHL\", \"CIP11BACHL\", \"CIP12BACHL\", \"CIP13BACHL\", \"CIP14BACHL\", \"CIP15BACHL\", \n",
    "        \"CIP16BACHL\", \"CIP19BACHL\", \"CIP22BACHL\", \"CIP23BACHL\", \"CIP24BACHL\", \"CIP25BACHL\", \n",
    "        \"CIP26BACHL\", \"CIP27BACHL\", \"CIP29BACHL\", \"CIP30BACHL\", \"CIP31BACHL\", \"CIP38BACHL\", \n",
    "        \"CIP39BACHL\", \"CIP40BACHL\", \"CIP41BACHL\", \"CIP42BACHL\", \"CIP43BACHL\", \"CIP44BACHL\", \n",
    "        \"CIP45BACHL\", \"CIP46BACHL\", \"CIP47BACHL\", \"CIP48BACHL\", \"CIP49BACHL\", \"CIP50BACHL\", \n",
    "        \"CIP51BACHL\", \"CIP52BACHL\", \"CIP54BACHL\", \"PCIP01\", \"PCIP03\", \"PCIP04\", \"PCIP05\", \n",
    "        \"PCIP09\", \"PCIP10\", \"PCIP11\", \"PCIP12\", \"PCIP13\", \"PCIP14\", \"PCIP15\", \"PCIP16\", \n",
    "        \"PCIP19\", \"PCIP22\", \"PCIP23\", \"PCIP24\", \"PCIP25\", \"PCIP26\", \"PCIP27\", \"PCIP29\", \n",
    "        \"PCIP30\", \"PCIP31\", \"PCIP38\", \"PCIP39\", \"PCIP40\", \"PCIP41\", \"PCIP42\", \"PCIP43\", \n",
    "        \"PCIP44\", \"PCIP45\", \"PCIP46\", \"PCIP47\", \"PCIP48\", \"PCIP49\", \"PCIP50\", \"PCIP51\", \n",
    "        \"PCIP52\", \"PCIP54\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[cols]\n",
    "df = df.loc[(df['PREDDEG'] == 3) & (df['CURROPER'] == 1)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the Earnings data from 2013-14 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2014 = data_2014.loc[data_2014['PREDDEG'] == 3]\n",
    "earn_cols = [\"UNITID\", \"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]\n",
    "df_earn = data_2014[earn_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_earn, on='UNITID', how='left')\n",
    "cols = cols+[\"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data for just Undergrad programs, correcting data types of columns and getting rid of unwanted literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"PREDDEG\", \"CURROPER\"], axis=1, inplace=True)\n",
    "df = df.replace('PrivacySuppressed', df.replace(['PrivacySuppressed'], [None]))\n",
    "wrong_data_type_cols = [\"INC_PCT_LO\", \"INC_PCT_M1\", \"INC_PCT_M2\", \"INC_PCT_H1\", \"INC_PCT_H2\", \n",
    "                        \"PAR_ED_PCT_1STGEN\", \"GRAD_DEBT_MDN\", \"WDRAW_DEBT_MDN\", \n",
    "                        \"GRAD_DEBT_MDN10YR\", \"RPY_3YR_RT\", \"RPY_5YR_RT\", \"RPY_7YR_RT\", \"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]\n",
    "df[wrong_data_type_cols] = df[wrong_data_type_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(col):\n",
    "    if df[col].dtype != 'O':\n",
    "        if col in [\"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]:\n",
    "            df[col].fillna(0, inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in the SAT_AVGs from merged Scorecard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_scores = pickle.load(open(\"final_sat.p\", \"rb\"))\n",
    "final_sat = {}\n",
    "for key in sat_scores:\n",
    "    if not any(c.isalpha() for c in key):\n",
    "        final_sat[int(key)] = sat_scores[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for opeid in final_sat:\n",
    "    df.loc[(df['OPEID'] == opeid), 'SAT_AVG'] = final_sat[opeid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the financial data columns for Public and Private Institutions and updating column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pub = [\"NPT4_PUB\", \"NPT41_PUB\", \"NPT42_PUB\", \"NPT43_PUB\", \"NPT44_PUB\", \"NPT45_PUB\"]\n",
    "cols_priv = [\"NPT4_PRIV\", \"NPT41_PRIV\", \"NPT42_PRIV\", \"NPT43_PRIV\", \"NPT44_PRIV\", \"NPT45_PRIV\"]\n",
    "for i in range(len(cols_pub)):\n",
    "    df[cols_pub[i]] = df[cols_pub[i]].fillna(df[cols_priv[i]])\n",
    "    \n",
    "df.rename(columns={\"NPT4_PUB\" : \"NPT4\", \"NPT41_PUB\" : \"NPT41\", \"NPT42_PUB\" : \"NPT42\", \n",
    "                   \"NPT43_PUB\" : \"NPT43\", \"NPT44_PUB\" : \"NPT44\", \"NPT45_PUB\" : \"NPT45\"}, \n",
    "          inplace=True)\n",
    "df.drop(cols_priv, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaN values for all financial data columns with mean values based on CONTROL type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    for col in ['COSTT4_A', 'TUITIONFEE_IN', 'TUITIONFEE_OUT', 'NPT4', 'NPT41', 'NPT42', 'NPT43', 'NPT44', 'NPT45']:\n",
    "        df.loc[(df['CONTROL'] == i), col] = df.loc[(df['CONTROL'] == i)][col].fillna(int(df.loc[(df['CONTROL'] == i)][col].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the remaining NaN values with median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For religious affiliation, if value not present then marking it as \"Not Reported (-1)\"\n",
    "df['RELAFFIL'] = df['RELAFFIL'].fillna(-1)\n",
    "\n",
    "for col in df.columns:\n",
    "    fill_nan(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning CIP columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cip_columns = [\"CIP01BACHL\", \"CIP03BACHL\", \"CIP04BACHL\", \"CIP05BACHL\", \"CIP09BACHL\", \n",
    "        \"CIP10BACHL\", \"CIP11BACHL\", \"CIP12BACHL\", \"CIP13BACHL\", \"CIP14BACHL\", \"CIP15BACHL\", \n",
    "        \"CIP16BACHL\", \"CIP19BACHL\", \"CIP22BACHL\", \"CIP23BACHL\", \"CIP24BACHL\", \"CIP25BACHL\", \n",
    "        \"CIP26BACHL\", \"CIP27BACHL\", \"CIP29BACHL\", \"CIP30BACHL\", \"CIP31BACHL\", \"CIP38BACHL\", \n",
    "        \"CIP39BACHL\", \"CIP40BACHL\", \"CIP41BACHL\", \"CIP42BACHL\", \"CIP43BACHL\", \"CIP44BACHL\", \n",
    "        \"CIP45BACHL\", \"CIP46BACHL\", \"CIP47BACHL\", \"CIP48BACHL\", \"CIP49BACHL\", \"CIP50BACHL\", \n",
    "        \"CIP51BACHL\", \"CIP52BACHL\", \"CIP54BACHL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cip_columns:\n",
    "    df[col] = df[col].clip_upper(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_crime_rate(dfc):\n",
    "    dfc['ZIP'] = dfc['ZIP'].apply(lambda x: str(x)[:5])\n",
    "    dfc = dfc.fillna(0)\n",
    "    remove_col = ['UNITID_P','INSTNM','BRANCH','Address','City','State','ZIP','sector_cd','Sector_desc',\n",
    "                  'men_total','women_total','Total','FILTER14','FILTER15', 'FILTER16','crime_count']\n",
    "    cols = list(dfc.columns.values)\n",
    "    cols = [ x for x in cols if x not in remove_col]\n",
    "    dfc['crime_count'] = dfc[cols].sum(axis=1)\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On Campus crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_excel(\"data/oncampuscrime141516.xls\")\n",
    "print(\"Calculating crime rate...\")\n",
    "df_crime = calc_crime_rate(df_crime)\n",
    "print(\"Writing Crime Rate into File...\")\n",
    "df_crime.to_excel(\"data/oncampuscrime141516.xls\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Campus crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_excel(\"data/noncampuscrime141516.xls\")\n",
    "print(\"Calculating crime rate...\")\n",
    "df_crime = calc_crime_rate(df_crime)\n",
    "print(\"Writing Crime Rate into File...\")\n",
    "df_crime.to_excel(\"data/noncampuscrime141516.xls\", encoding='utf-8', index=False)\n",
    "print(\"Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Data set with crime rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc = pd.read_excel(\"data/noncampuscrime141516.xls\")\n",
    "dfc = pd.read_excel(\"data/oncampuscrime141516.xls\")\n",
    "dfnc = dfnc[['ZIP','crime_count','State']]\n",
    "dfc = dfc[['ZIP','crime_count','State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.merge(dfc, dfnc, on='ZIP')\n",
    "dfc.head()\n",
    "dfc['crime_count'] = dfc['crime_count_x'] + dfc['crime_count_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfcrime = dfc[['ZIP','crime_count','State_x']]\n",
    "dfcrime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata = df.copy()\n",
    "# print(dfdata.columns.values)\n",
    "dfdata.shape\n",
    "dfcrime= dfcrime.drop_duplicates('ZIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Zip code in original Data set and crime rate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata['ZIP'] = dfdata['ZIP'].apply(lambda x: x.zfill(5))\n",
    "dfdata['ZIP'] = dfdata['ZIP'].apply(lambda x: x[:5])\n",
    "dfcrime['ZIP'] = dfcrime['ZIP'].apply(lambda x: str(x).zfill(5))\n",
    "dfcrime['ZIP'] = dfcrime['ZIP'].apply(lambda x: x[:5])\n",
    "dfd = pd.merge(dfdata, dfcrime, on=\"ZIP\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill Null crime_count with 0\n",
    "dfd['crime_count'] = dfd['crime_count'].fillna(0)\n",
    "print(\"Null: \"+str(dfd['crime_count'].isnull().sum()))\n",
    "dfavg = dfd.loc[dfd['crime_count']!=0]\n",
    "# Calculate Crime rate average per State\n",
    "dfdd = dfavg.groupby('State_x', as_index=False)['crime_count'].mean()\n",
    "dfd = pd.merge(dfd, dfdd, left_on=\"STABBR\", right_on = \"State_x\", how='left')\n",
    "print(dfd.head())\n",
    "# Fill Crime rate average in missing data\n",
    "dfd['crime_count_y'] = dfd['crime_count_y'].fillna(0)\n",
    "dfd.loc[dfd['crime_count_x']==0, 'crime_count_x'] = dfd['crime_count_y']\n",
    "print(\"Zero: \"+str(len(dfd.loc[dfd['crime_count_x']==0])))\n",
    "print(\"Null: \"+str(dfd['crime_count_x'].isnull().sum()))\n",
    "dfd.drop(['State_x_x','State_x_y','crime_count_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing Crime Rate into dataset\")\n",
    "df['CRIME_COUNT'] = dfd['crime_count_x']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fetch Temperature data from temperatures.json and add it to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temperatures(df_temp):\n",
    "    d=json.load(open('temperatures.json'))\n",
    "    temps=[]\n",
    "    zips=df['ZIP'].tolist()\n",
    "    zips=[zips[i].split(\"-\")[0] for i in range(len(zips))]\n",
    "    for i in range(len(zips)):\n",
    "        temps.append(d[zips[i]])\n",
    "    cols=np.asarray(temps,dtype=float)\n",
    "    df_temp['SPRING_TAVG'], df_temp['SUMMER_TAVG'], df_temp['FALL_TAVG'], df_temp['WINTER_TAVG'] = cols[:,0], cols[:,1], cols[:,2], cols[:,3]\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_temperatures(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cleaned data to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
