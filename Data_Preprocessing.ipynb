{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/MERGED2015_16_PP.csv\"\n",
    "data = pd.read_csv(path, low_memory=False)\n",
    "\n",
    "path_2014 = \"data/MERGED2013_14_PP.csv\"\n",
    "data_2014 = pd.read_csv(path_2014, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing out columns of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [\"OPEID\", \"UNITID\", \"INSTNM\", \"CITY\", \"STABBR\", \"ZIP\", \"CURROPER\", \"MAIN\", \"PREDDEG\", \"HIGHDEG\", \n",
    "        \"CONTROL\", \"RELAFFIL\", \"DISTANCEONLY\", \"ADM_RATE\", \"SAT_AVG\", \"ACTCMMID\", \"UGDS\", \"UGDS_WHITE\", \"UGDS_BLACK\", \"UGDS_HISP\", \n",
    "        \"UGDS_ASIAN\", \"UGDS_AIAN\", \"UGDS_NHPI\", \"UGDS_2MOR\", \"UGDS_NRA\", \"UGDS_UNKN\", \n",
    "        \"HBCU\", \"PBI\", \"ANNHI\", \"TRIBAL\", \"HSI\", \"NANTI\", \"MENONLY\", \"WOMENONLY\", \"PPTUG_EF\", \n",
    "        \"UG25ABV\", \"INC_PCT_LO\", \"INC_PCT_M1\", \"INC_PCT_M2\", \"INC_PCT_H1\", \"INC_PCT_H2\", \n",
    "        \"PAR_ED_PCT_1STGEN\", \"NPT4_PUB\", \"NPT4_PRIV\", \"COSTT4_A\", \"TUITIONFEE_IN\", \"TUITIONFEE_OUT\", \n",
    "        \"NPT41_PUB\", \"NPT42_PUB\", \"NPT43_PUB\", \"NPT44_PUB\", \"NPT45_PUB\", \"NPT41_PRIV\", \"NPT42_PRIV\", \n",
    "        \"NPT43_PRIV\", \"NPT44_PRIV\", \"NPT45_PRIV\", \"PCTFLOAN\", \"PCTPELL\", \"GRAD_DEBT_MDN\", \n",
    "        \"WDRAW_DEBT_MDN\", \"GRAD_DEBT_MDN10YR\", \"CDR3\", \"RPY_3YR_RT\", \n",
    "        \"RPY_5YR_RT\", \"RPY_7YR_RT\", \"C150_4\", \"D150_4\", \"CIP01BACHL\", \"CIP03BACHL\", \"CIP04BACHL\", \"CIP05BACHL\", \"CIP09BACHL\", \n",
    "        \"CIP10BACHL\", \"CIP11BACHL\", \"CIP12BACHL\", \"CIP13BACHL\", \"CIP14BACHL\", \"CIP15BACHL\", \n",
    "        \"CIP16BACHL\", \"CIP19BACHL\", \"CIP22BACHL\", \"CIP23BACHL\", \"CIP24BACHL\", \"CIP25BACHL\", \n",
    "        \"CIP26BACHL\", \"CIP27BACHL\", \"CIP29BACHL\", \"CIP30BACHL\", \"CIP31BACHL\", \"CIP38BACHL\", \n",
    "        \"CIP39BACHL\", \"CIP40BACHL\", \"CIP41BACHL\", \"CIP42BACHL\", \"CIP43BACHL\", \"CIP44BACHL\", \n",
    "        \"CIP45BACHL\", \"CIP46BACHL\", \"CIP47BACHL\", \"CIP48BACHL\", \"CIP49BACHL\", \"CIP50BACHL\", \n",
    "        \"CIP51BACHL\", \"CIP52BACHL\", \"CIP54BACHL\", \"PCIP01\", \"PCIP03\", \"PCIP04\", \"PCIP05\", \n",
    "        \"PCIP09\", \"PCIP10\", \"PCIP11\", \"PCIP12\", \"PCIP13\", \"PCIP14\", \"PCIP15\", \"PCIP16\", \n",
    "        \"PCIP19\", \"PCIP22\", \"PCIP23\", \"PCIP24\", \"PCIP25\", \"PCIP26\", \"PCIP27\", \"PCIP29\", \n",
    "        \"PCIP30\", \"PCIP31\", \"PCIP38\", \"PCIP39\", \"PCIP40\", \"PCIP41\", \"PCIP42\", \"PCIP43\", \n",
    "        \"PCIP44\", \"PCIP45\", \"PCIP46\", \"PCIP47\", \"PCIP48\", \"PCIP49\", \"PCIP50\", \"PCIP51\", \n",
    "        \"PCIP52\", \"PCIP54\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2059, 144)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[cols]\n",
    "df = df.loc[(df['PREDDEG'] == 3) & (df['CURROPER'] == 1)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the Earnings data from 2013-14 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2014 = data_2014.loc[data_2014['PREDDEG'] == 3]\n",
    "earn_cols = [\"UNITID\", \"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]\n",
    "df_earn = data_2014[earn_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_earn, on='UNITID', how='left')\n",
    "cols = cols+[\"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data for just Undergrad programs, correcting data types of columns and getting rid of unwanted literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop([\"PREDDEG\", \"CURROPER\"], axis=1, inplace=True)\n",
    "df = df.replace('PrivacySuppressed', df.replace(['PrivacySuppressed'], [None]))\n",
    "wrong_data_type_cols = [\"INC_PCT_LO\", \"INC_PCT_M1\", \"INC_PCT_M2\", \"INC_PCT_H1\", \"INC_PCT_H2\", \n",
    "                        \"PAR_ED_PCT_1STGEN\", \"GRAD_DEBT_MDN\", \"WDRAW_DEBT_MDN\", \n",
    "                        \"GRAD_DEBT_MDN10YR\", \"RPY_3YR_RT\", \"RPY_5YR_RT\", \"RPY_7YR_RT\", \"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]\n",
    "df[wrong_data_type_cols] = df[wrong_data_type_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_nan(col):\n",
    "    if df[col].dtype != 'O':\n",
    "        if col in [\"MD_EARN_WNE_P6\", \"MD_EARN_WNE_P10\"]:\n",
    "            df[col].fillna(0, inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in the SAT_AVGs from merged Scorecard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_scores = pickle.load(open(\"final_sat.p\", \"rb\"))\n",
    "final_sat = {}\n",
    "for key in sat_scores:\n",
    "    if not any(c.isalpha() for c in key):\n",
    "        final_sat[int(key)] = sat_scores[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for opeid in final_sat:\n",
    "    df.loc[(df['OPEID'] == opeid), 'SAT_AVG'] = final_sat[opeid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the financial data columns for Public and Private Institutions and updating column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_pub = [\"NPT4_PUB\", \"NPT41_PUB\", \"NPT42_PUB\", \"NPT43_PUB\", \"NPT44_PUB\", \"NPT45_PUB\"]\n",
    "cols_priv = [\"NPT4_PRIV\", \"NPT41_PRIV\", \"NPT42_PRIV\", \"NPT43_PRIV\", \"NPT44_PRIV\", \"NPT45_PRIV\"]\n",
    "for i in range(len(cols_pub)):\n",
    "    df[cols_pub[i]] = df[cols_pub[i]].fillna(df[cols_priv[i]])\n",
    "    \n",
    "df.rename(columns={\"NPT4_PUB\" : \"NPT4\", \"NPT41_PUB\" : \"NPT41\", \"NPT42_PUB\" : \"NPT42\", \n",
    "                   \"NPT43_PUB\" : \"NPT43\", \"NPT44_PUB\" : \"NPT44\", \"NPT45_PUB\" : \"NPT45\"}, \n",
    "          inplace=True)\n",
    "df.drop(cols_priv, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaN values for all financial data columns with mean values based on CONTROL type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    for col in ['COSTT4_A', 'TUITIONFEE_IN', 'TUITIONFEE_OUT', 'NPT4', 'NPT41', 'NPT42', 'NPT43', 'NPT44', 'NPT45']:\n",
    "        df.loc[(df['CONTROL'] == i), col] = df.loc[(df['CONTROL'] == i)][col].fillna(int(df.loc[(df['CONTROL'] == i)][col].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the remaining NaN values with median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For religious affiliation, if value not present then marking it as \"Not Reported (-1)\"\n",
    "df['RELAFFIL'] = df['RELAFFIL'].fillna(-1)\n",
    "\n",
    "for col in df.columns:\n",
    "    fill_nan(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning CIP columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cip_columns = [\"CIP01BACHL\", \"CIP03BACHL\", \"CIP04BACHL\", \"CIP05BACHL\", \"CIP09BACHL\", \n",
    "        \"CIP10BACHL\", \"CIP11BACHL\", \"CIP12BACHL\", \"CIP13BACHL\", \"CIP14BACHL\", \"CIP15BACHL\", \n",
    "        \"CIP16BACHL\", \"CIP19BACHL\", \"CIP22BACHL\", \"CIP23BACHL\", \"CIP24BACHL\", \"CIP25BACHL\", \n",
    "        \"CIP26BACHL\", \"CIP27BACHL\", \"CIP29BACHL\", \"CIP30BACHL\", \"CIP31BACHL\", \"CIP38BACHL\", \n",
    "        \"CIP39BACHL\", \"CIP40BACHL\", \"CIP41BACHL\", \"CIP42BACHL\", \"CIP43BACHL\", \"CIP44BACHL\", \n",
    "        \"CIP45BACHL\", \"CIP46BACHL\", \"CIP47BACHL\", \"CIP48BACHL\", \"CIP49BACHL\", \"CIP50BACHL\", \n",
    "        \"CIP51BACHL\", \"CIP52BACHL\", \"CIP54BACHL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cip_columns:\n",
    "    df[col] = df[col].clip_upper(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_crime_rate(dfc):\n",
    "    dfc['ZIP'] = dfc['ZIP'].apply(lambda x: str(x)[:5])\n",
    "    dfc = dfc.fillna(0)\n",
    "    remove_col = ['UNITID_P','INSTNM','BRANCH','Address','City','State','ZIP','sector_cd','Sector_desc',\n",
    "                  'men_total','women_total','Total','FILTER14','FILTER15', 'FILTER16']\n",
    "    cols = list(dfc.columns.values)\n",
    "    cols = [ x for x in cols if x not in remove_col]\n",
    "    dfc['crime_count'] = dfc[cols].sum(axis=1)\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On Campus crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating crime rate...\n",
      "Writing Crime Rate into File...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating crime rate...\")\n",
    "df_crime = calc_crime_rate(df_crime)\n",
    "print(\"Writing Crime Rate into File...\")\n",
    "df_crime.to_excel(\"data/oncampuscrime141516.xls\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Campus crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating crime rate...\n",
      "Writing Crime Rate into File...\n",
      "Successful\n"
     ]
    }
   ],
   "source": [
    "df_crime = pd.read_excel(\"data/noncampuscrime141516.xls\")\n",
    "print(\"Calculating crime rate...\")\n",
    "df_crime = calc_crime_rate(df_crime)\n",
    "print(\"Writing Crime Rate into File...\")\n",
    "df_crime.to_excel(\"data/noncampuscrime141516.xls\", encoding='utf-8', index=False)\n",
    "print(\"Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Data set with crime rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc = pd.read_excel(\"data/noncampuscrime141516.xls\")\n",
    "dfc = pd.read_excel(\"data/oncampuscrime141516.xls\")\n",
    "dfnc = dfnc[['ZIP','crime_count','State']]\n",
    "dfc = dfc[['ZIP','crime_count','State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.merge(dfc, dfnc, on='ZIP')\n",
    "dfc.head()\n",
    "dfc['crime_count'] = dfc['crime_count_x'] + dfc['crime_count_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>crime_count</th>\n",
       "      <th>State_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35762</td>\n",
       "      <td>248</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35294</td>\n",
       "      <td>652</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35801</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35801</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35801</td>\n",
       "      <td>8</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZIP  crime_count State_x\n",
       "0  35762          248      AL\n",
       "1  35294          652      AL\n",
       "2  35801            0      AL\n",
       "3  35801            0      AL\n",
       "4  35801            8      AL"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcrime = dfc[['ZIP','crime_count','State_x']]\n",
    "dfcrime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata = df\n",
    "# print(dfdata.columns.values)\n",
    "dfdata.shape\n",
    "dfcrime= dfcrime.drop_duplicates('ZIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Zip code in original Data set and crime rate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata['ZIP'] = dfdata['ZIP'].apply(lambda x: x.zfill(5))\n",
    "dfdata['ZIP'] = dfdata['ZIP'].apply(lambda x: x[:5])\n",
    "dfcrime['ZIP'] = dfcrime['ZIP'].apply(lambda x: str(x).zfill(5))\n",
    "dfcrime['ZIP'] = dfcrime['ZIP'].apply(lambda x: x[:5])\n",
    "dfd = pd.merge(dfdata, dfcrime, on=\"ZIP\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null: 0\n",
      "     OPEID  UNITID                               INSTNM        CITY STABBR  \\\n",
      "0   100200  100654             Alabama A & M University      Normal     AL   \n",
      "1   105200  100663  University of Alabama at Birmingham  Birmingham     AL   \n",
      "2  2503400  100690                   Amridge University  Montgomery     AL   \n",
      "3   105500  100706  University of Alabama in Huntsville  Huntsville     AL   \n",
      "4   100500  100724             Alabama State University  Montgomery     AL   \n",
      "\n",
      "     ZIP  MAIN  HIGHDEG  CONTROL  RELAFFIL      ...        PCIP50  PCIP51  \\\n",
      "0  35762     1        4        1      -1.0      ...        0.0258  0.0000   \n",
      "1  35294     1        4        1      -1.0      ...        0.0376  0.2231   \n",
      "2  36117     1        4        2      74.0      ...        0.0000  0.0000   \n",
      "3  35899     1        4        1      -1.0      ...        0.0288  0.1892   \n",
      "4  36104     1        4        1      -1.0      ...        0.0473  0.0926   \n",
      "\n",
      "   PCIP52  PCIP54  MD_EARN_WNE_P6  MD_EARN_WNE_P10  crime_count_x  State_x_x  \\\n",
      "0  0.1479  0.0000         23100.0          29900.0          248.0         AL   \n",
      "1  0.1837  0.0188         34000.0          40200.0          652.0         AL   \n",
      "2  0.3962  0.0000         33200.0          40100.0            0.0         AL   \n",
      "3  0.2072  0.0117         35500.0          45600.0          664.0         AL   \n",
      "4  0.0983  0.0113         21000.0          26700.0          973.0         AL   \n",
      "\n",
      "   State_x_y  crime_count_y  \n",
      "0         AL     443.304348  \n",
      "1         AL     443.304348  \n",
      "2         AL     443.304348  \n",
      "3         AL     443.304348  \n",
      "4         AL     443.304348  \n",
      "\n",
      "[5 rows x 142 columns]\n",
      "Zero: 0\n",
      "Null: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill Null crime_count with 0\n",
    "dfd['crime_count'] = dfd['crime_count'].fillna(0)\n",
    "print(\"Null: \"+str(dfd['crime_count'].isnull().sum()))\n",
    "dfavg = dfd.loc[dfd['crime_count']!=0]\n",
    "# Calculate Crime rate average per State\n",
    "dfdd = dfavg.groupby('State_x', as_index=False)['crime_count'].mean()\n",
    "dfd = pd.merge(dfd, dfdd, left_on=\"STABBR\", right_on = \"State_x\", how='left')\n",
    "print(dfd.head())\n",
    "# Fill Crime rate average in missing data\n",
    "dfd.loc[dfd['crime_count_x']==0, 'crime_count_x'] = dfd['crime_count_y']\n",
    "print(\"Zero: \"+str(len(dfd.loc[dfd['crime_count_x']==0])))\n",
    "print(\"Null: \"+str(dfd['crime_count_x'].isnull().sum()))\n",
    "dfd = dfd.drop(columns=['State_x_x','State_x_y','crime_count_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Crime Rate into File...\n",
      "Successful\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing Crime Rate into File...\")\n",
    "df['CRIME_COUNT'] = dfd['crime_count_x']\n",
    "print(\"Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cleaned data to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fetch Temperature data from temperatures.json and add it to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def get_temperatures():\n",
    "    d=json.load(open('temperatures.json'))\n",
    "    temps=[]\n",
    "    df=pd.read_csv('cleaned_data.csv', low_memory=False)\n",
    "    zips=df['ZIP'].tolist()\n",
    "    zips=[zips[i].split(\"-\")[0] for i in range(len(zips))]\n",
    "    for i in range(len(zips)):\n",
    "        temps.append(d[zips[i]])\n",
    "    cols=np.asarray(temps,dtype=float)\n",
    "    df['SPRING_TAVG'], df['SUMMER_TAVG'], df['FALL_TAVG'], df['WINTER_TAVG'] = cols[:,0], cols[:,1], cols[:,2], cols[:,3]\n",
    "    df.to_csv(\"cleaned_data.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
